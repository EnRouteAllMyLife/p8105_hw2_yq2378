---
title: "p8105_hw2_yq2378"
author: "Qi Yumeng"
date: "2023-09-29"
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

```{r load lib}
library("tidyverse")
library("lubridate")
library("readxl")
```

# Problem 1

The file “pols-month” contains 822 observations of 9 variables related to the number of national politicians who are democratic or republican at any given time. `president` is the indicator of whether the president was republican or democratic on the associated date, it's originate from `prez_dem` and `prez_gop`. `gov_gop`, `sen_gop` and `rep_gop` respectively stands for the number of republican governors,senators and representatives on the associated date. `gov_dem`, `sen_dem` and `rep_dem` stands for the similar meanings for democratic. The records start from January,1947 to June, 2015.  
The file “snp” contains 787 observations of 2 variables related to Standard & Poor’s stock market index (S&P), often used as a representative measure of stock market as a whole. `close` indicates the closing values of the S&P stock index on the associated date. The records start from January,1950 to July, 2015.   
The file “unemployment” contains 68 observations of 13 variables describing percentage of unemployment in certain month of the associated year, see `unemployment_rate`. The records start from January,1948 to December, 2015.   

The merged file is joined by `year` and `month`. It contains 822 observations of 11 variables. The records start from January,1947 to June, 2015.  


```{r df_pols}
df_pols = read_csv("./dataset/pols-month.csv")
head(df_pols)
df_pols = df_pols %>%
  separate(mon, into = c("year", "month", "day"), sep = "-") %>%
  mutate(month = case_when(
    month == "01" ~ "January",
    month == "02" ~ "February",
    month == "03" ~ "March",
    month == "04" ~ "April",
    month == "05" ~ "May",
    month == "06" ~ "June",
    month == "07" ~ "July",
    month == "08" ~ "August",
    month == "09" ~ "September",
    month == "10" ~ "October",
    month == "11" ~ "November",
    month == "12" ~ "December"
  )) %>%
  arrange(as.numeric(year),as.numeric(month))%>%
  mutate(president = case_when(
    prez_dem == 1 ~ "dem",
    prez_gop != 0 ~ "gop"
  )) %>%
  select(-day, -prez_dem,-prez_gop) 
head(df_pols)
```



```{r df_snp}
df_snp = read_csv("./dataset/snp.csv")
head(df_snp)
# notcie 	6/2/58 should be 1958 rather than 2058
df_snp = df_snp %>%
  separate(date, into = c("month", "day","year"), sep = "/") %>%
  mutate(year = ifelse(as.numeric(year) >= 50, 1900 + as.numeric(year) , 2000 + as.numeric(year)))%>%
  select(-day) %>%
  select(year, month, close)%>%
  arrange(as.numeric(year),as.numeric(month)) %>%
  mutate(month = case_when(
    month == "1" ~ "January",
    month == "2" ~ "February",
    month == "3" ~ "March",
    month == "4" ~ "April",
    month == "5" ~ "May",
    month == "6" ~ "June",
    month == "7" ~ "July",
    month == "8" ~ "August",
    month == "9" ~ "September",
    month == "10" ~ "October",
    month == "11" ~ "November",
    month == "12" ~ "December"
  ),
  year = as.character(year))  
head(df_snp)
```

```{r df_unemp}
df_unemp = read_csv("./dataset/unemployment.csv")
head(df_unemp)
# Create a data frame with month abbreviation and full name mapping
month_mapping <- data.frame(
  MonthAbbreviation = month.abb,
  MonthFullName = month.name,
  stringsAsFactors = FALSE
)

df_unemp = df_unemp %>% 
  pivot_longer(Jan:Dec,names_to = "month_abb", values_to = "unemployment_rate") %>%
  left_join(month_mapping, by = c("month_abb" = "MonthAbbreviation")) %>% 
  select(-month_abb) %>%
  rename(year = Year, month = MonthFullName) %>% 
  select(year, month, unemployment_rate)%>% 
  mutate(year = as.character(year))
head(df_unemp)
df_final = df_pols %>% left_join(df_snp,by = c('year','month')) %>% left_join(df_unemp,by = c('year','month'))
```
# Problem 2

```{r TrashWheel}
df_mr_trash = read_excel(path = "./dataset/202309 Trash Wheel Collection Data.xlsx",
                      sheet = "Mr. Trash Wheel",
                      skip = 0,
                      col_names = TRUE,
                      range = "A2:N586") %>%
   janitor::clean_names() %>%
  filter(!is.na(weight_tons)) %>%  # omit rows that do not include dumpster-specific data
  mutate(homes_powered_new = weight_tons*500/30,
         trash_name = "Mr. Trash Wheel")
df_pro_trash = read_excel(path = "./dataset/202309 Trash Wheel Collection Data.xlsx",
                      sheet = "Professor Trash Wheel",
                      skip = 0,
                      col_names = TRUE,
                      range = "A2:M108") %>%
   janitor::clean_names() %>%
   filter(!is.na(weight_tons)) %>%
   mutate(homes_powered_new = weight_tons*500/30,
          trash_name = "Professor Trash Wheel",
          year = as.character(year))
df_cap_trash = read_excel(path = "./dataset/202309 Trash Wheel Collection Data.xlsx",
                      sheet = "Captain Trash Wheel",
                      skip = 0,
                      col_names = TRUE,
                      range = "A2:K30") %>%
   janitor::clean_names() %>%
   filter(!is.na(weight_tons)) %>%
   mutate(homes_powered_new = weight_tons*500/30,
          trash_name = "Captain Trash Wheel",
          year = as.character(year))
df_trash = bind_rows(df_mr_trash,df_pro_trash, df_cap_trash)
```

These data encompass information from three trash-collecting devices: Mr. Trash Wheel, Professor Trash Wheel, and Gwynnda. The combined dataset has `r nrow(df_trash)` observations of `r ncol(df_trash)` variables. It has time related variables like `data`, `month` and `year`. `weight_tons` shows the total weight of the trash. It also has detailed amount of all kinds of trash, like `cigarette_butt`,`glass_bottles`, `grocery_bags` etc.`trash_name` helps to distinguish which trash wheel is used.

The total weight of trash collected by Professor Trash Wheel is `r df_trash %>% filter(trash_name == "Professor Trash Wheel") %>% summarise(sum(weight_tons))`.     
The total number of cigarette butts collected by Gwynnda in July of 2021 is `r df_trash %>% filter(trash_name == "Captain Trash Wheel" & year == "2021" & month == "July") %>% summarise(sum(cigarette_butts))`.


# Problem 3

```{r baseline}
df_baseline = read_csv("./dataset/MCI_baseline.csv", skip = 1, na = c(".", "NA", ""), show_col_types = FALSE) %>%
              janitor::clean_names() %>%
              mutate(sex = case_match(sex, 0 ~ "female", 1 ~ "male"),
                     sex = as.factor(sex),
                     apoe4 = case_match(apoe4, 0 ~ "non_carrier", 1~"carrier"),
                     apoe4 = as.factor(apoe4))  # remove no MCI at baseline
          
df_baseline %>%  summarise(cnt = n(), 
                           age_avg = mean(current_age),
                           proportion = sum(abs(as.numeric(sex )-2)* abs(as.numeric(apoe4)-2))/sum(abs(as.numeric(sex )-2)))
```

We import the MCI_baseline dataset by using `read_csv`,skipping the first row for its the description and replacing all the ".", "" "NA" if any to NA. Instead of using "col_types", we directly encode `sex` and `apoe4` to factors, which is intuitive and easy to calculate. The factor mapping is {`sex`: female: 1, male:0}, {`apoe4`: carrier: 1, non_carrier: 2}. The number of total participants is `r nrow(df_baseline)`, `r sum(!is.na(df_baseline$age_at_onset))` participants have developed MCI, among which `r sum(df_baseline$age_at_onset <= df_baseline$current_age, na.rm = TRUE)` have developed MCI before the study and should be excluded.

```{r valid}
#df_baseline = df_baseline %>%  filter(!is.na(age_at_onset) & age_at_onset>current_age) 
df_baseline = df_baseline %>%  filter(age_at_onset>current_age | is.na(age_at_onset)) 
df_baseline %>% summarise(mci_cnt = n(), 
                          age_avg = mean(current_age),
                          proportion = sum(abs(as.numeric(sex )-2)* abs(as.numeric(apoe4)-2))/sum(abs(as.numeric(sex )-2)))

```
After removing the invalid data,the average baseline age is around 65.61	and the proportion of women in the study are APOE4 carriers is around 30.00%.

Similarly, import the dataset, skip the first row, and replace "NA" with NAs. Since we already know that this dataset consists of many numeric variables, we use col_types to specify the data types. Afterward, use clean_names to standardize the column names. The dataset includes a primary key `student_id`, and the biomarker values are recorded at various time points, starting from `baseline`, progressing through `time_2`, `time_4`, `time_6`, and ending at `time_8`. By using the 'skim' function, we can gain insights into the distribution and characteristics of longitudinally observed biomarker values.

Use `pivot_longer()` to transform the data from wide to long. Use `values_drop_na = TRUE` to drop NA. This make amyloid dataset much more like a dataset of longitudinally observed biomarker values. (But from my standpoint, this transformation make the data lose the unique key and kind of redundant. So I choose to use the original dataset instead of the long one. Hopeing this is acceptable. )
```{r amyloid}
df_amyloid = read_csv("./dataset/mci_amyloid.csv", skip = 1, na = c(".", "NA", "") ,
                      col_types = cols(
                                       `Study ID` = col_integer(),
                                        Baseline = col_double(),
                                       `Time 2` = col_double(),
                                       `Time 4` = col_double(),
                                       `Time 6` = col_double(),
                                       `Time 8` = col_double())) %>%
              janitor::clean_names() 
skimr::skim(df_amyloid) 

df_amyloid %>% pivot_longer(cols = c("baseline",starts_with("time_")), names_to = "time_tag",values_drop_na = TRUE)
```

```{r output }
df_mci = df_baseline %>% inner_join(df_amyloid, by = c("id" = "study_id"))
head(df_mci)
write_csv(df_mci, file = "./dataset/mci_result.csv")
```
After inner join, there is only `r nrow(df_mci)` observations of `r ncol(df_mci)` variables, meaning there are `r nrow(df_baseline) - nrow(df_mci)` participants got excluded from the filtered baseline dataset and `r nrow(df_amyloid) - nrow(df_mci)` participants got excluded from the amyloid dataset. Indicating there might be lost to follow up cases. 